# Awesome-LLM-Hallucination-Detection-and-Mitigation




## Hallucination Detection 

### Fact-checking 

### Uncertainty Analysis 

### Consistency Measure 



## Hallucination Mitigation 

### Model Calibration 

- [Chuang2024] DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models in *ICLR* 2024. [\[paper\]](https://arxiv.org/abs/2309.03883)[\[code\]](https://github.com/voidism/DoLa)

- [Zhou2025] HaDeMiF: Hallucination Detection and Mitigation in Large Language Models in *ICLR* 2025. [\[paper\]](https://openreview.net/pdf?id=VwOYxPScxB)[\[code\]]()
